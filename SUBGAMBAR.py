# -*- coding: utf-8 -*-
"""Untitled3_(1) (2).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oltxtxBxm0uZL8FQ7NGVtQiU-W4Z87ex
"""

import json

# Membuat file kaggle.json dengan API token Anda
api_token = {"username":"krisnandi9998","key":"2d15c9eb5dd2bb51786765892d7218d9"}

# Membuat folder kaggle dan menyimpan token API
!mkdir -p ~/.kaggle
with open('/root/.kaggle/kaggle.json', 'w') as file:
    json.dump(api_token, file)

# Mengubah izin akses untuk file API
!chmod 600 ~/.kaggle/kaggle.json

# Verifikasi kredensial
!kaggle datasets list

# Mendownload dataset bunga dari Kaggle
!kaggle datasets download -d alxmamaev/flowers-recognition

# Ekstrak file dataset
!unzip flowers-recognition.zip -d flowers_dataset/

import os
import shutil

dataset_path = 'flowers_dataset/flowers'
class_to_remove = 'sunflower'  # Kelas yang ingin dihapus

# Pastikan path sesuai dengan struktur dataset
if not os.path.exists(dataset_path):
    print(f"Path {dataset_path} tidak ditemukan!")
else:
    print(f"Path {dataset_path} ditemukan. Memulai proses...")

# Path ke kelas yang akan dihapus
class_path = os.path.join(dataset_path, class_to_remove)

# Cek apakah kelas tersebut ada, jika ada maka hapus foldernya
if os.path.exists(class_path):
    shutil.rmtree(class_path)  # Hapus folder dan semua isinya
    print(f"Kelas '{class_to_remove}' dan semua isinya telah dihapus.")
else:
    print(f"Kelas '{class_to_remove}' tidak ditemukan dalam dataset.")

# Verifikasi bahwa kelas telah dihapus
remaining_classes = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]
print(f"Kelas yang tersisa dalam dataset: {remaining_classes}")

import matplotlib.pyplot as plt

# Visualisasi Distribusi Kelas
def plot_class_distribution(dataset_directory):
    classes = os.listdir(dataset_directory)
    class_counts = {}
    for cls in classes:
        class_path = os.path.join(dataset_directory, cls)
        if os.path.isdir(class_path):
            class_counts[cls] = len(os.listdir(class_path))

    plt.figure(figsize=(12, 6))
    plt.bar(class_counts.keys(), class_counts.values(), color='red')
    plt.xlabel('KELAS')
    plt.ylabel('JUMLAH GAMBAR')
    plt.title('DISTRIBUSI KELAS PADA DATASET')
    plt.xticks(rotation=45, ha='right')
    plt.grid(axis='y')
    plt.tight_layout()
    plt.show()

# Menampilkan distribusi kelas
dataset_directory = 'flowers_dataset/flowers'
plot_class_distribution(dataset_directory)

import numpy as np
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import Callback, ModelCheckpoint, EarlyStopping

# Augmentasi dan scaling gambar
train_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2,  # 20% untuk validasi
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)

# Generator untuk data training
train_generator = train_datagen.flow_from_directory(
    'flowers_dataset/flowers',
    target_size=(150, 150),  # Handling resolusi gambar yang tidak seragam
    batch_size=32,
    class_mode='categorical',
    subset='training'  # Bagian training
)

# Generator untuk data validasi
validation_generator = train_datagen.flow_from_directory(
    'flowers_dataset/flowers',
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical',
    subset='validation'  # Bagian validasi
)

# Distribusi kelas berdasarkan dataset karena tidak seimbang dengan oversampling
class_weights = {
    0: 1052/984,  # Tulip (jumlah gambar 984)
    1: 1052/764,  # Daisy (jumlah gambar 764)
    2: 1.0,       # Dandelion (jumlah gambar 1052, baseline)
    3: 1052/784   # Rose (jumlah gambar 784)
}

# Callback untuk menghentikan training ketika val_accuracy > 90%
class AccuracyThresholdStopping(Callback):
    def __init__(self, threshold=0.90, monitor='val_accuracy'):
        super(AccuracyThresholdStopping, self).__init__()
        self.threshold = threshold
        self.monitor = monitor

    def on_epoch_end(self, epoch, logs=None):
        current = logs.get(self.monitor)
        if current is not None and current >= self.threshold:
            print(f"\nEpoch {epoch+1}: {self.monitor} has reached {current:.2f}, stopping training.")
            self.model.stop_training = True

# Callback untuk menyimpan model terbaik
checkpoint = ModelCheckpoint('best_model.keras', monitor='val_accuracy', save_best_only=True)

from tensorflow.keras.applications import Xception #transfer learning
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Flatten, Dropout
from tensorflow.keras.optimizers import Adam

# Muat model transfer learning tanpa lapisan klasifikasi akhir dan tanpa bobot atas
base_model = Xception(weights='imagenet', include_top=False, input_shape=(150, 150, 3))

# Bekukan lapisan-lapisan pada model transfer learning
for layer in base_model.layers:
    layer.trainable = False

# Tambahkan lapisan klasifikasi kustom di atas model transfer learning
x = base_model.output
x = Flatten()(x)
x = Dense(512, activation='relu')(x)
x = Dropout(0.5)(x)
predictions = Dense(4, activation='softmax')(x)  # 4 kelas bunga

# Buat model akhir
model = Model(inputs=base_model.input, outputs=predictions)

# Callback untuk menghentikan training jika tidak ada peningkatan selama 15 epoch
early_stop = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)

# Compile model dengan learning rate kecil
model.compile(optimizer=Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])

# Latih model
history = model.fit(
    train_generator,
    epochs=100,
    validation_data=validation_generator,
    class_weight=class_weights,
    callbacks=[checkpoint,early_stop, AccuracyThresholdStopping(threshold=0.90)]
)

from tensorflow.keras.models import load_model

# Muat model terbaik
best_model = load_model('best_model.keras')

# Evaluasi model terbaik
loss, accuracy = best_model.evaluate(validation_generator)
print(f'Validation Loss: {loss}')
print(f'Validation Accuracy: {accuracy}')

# Plot Akurasi
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Plot Loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

!pip install tensorflowjs
import tensorflow as tf
import tensorflowjs as tfjs

# Menyimpan model dalam format SavedModel
model.export('saved_model/flowers_model') # Use model.export to save in SavedModel format

# Mengonversi model Keras ke format TF-Lite
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
with open('model.tflite', 'wb') as f:
    f.write(tflite_model)

# Mengonversi dan menyimpan model ke format TensorFlow.js
tfjs.converters.save_keras_model(model, 'tfjs_model')

from google.colab import files

# Unduh file model TFLite
files.download('model.tflite')

# Unduh file SavedModel (biasanya berupa folder, jadi harus dijadikan zip dulu)
!zip -r saved_model.zip saved_model/
files.download('saved_model.zip')

# Unduh model TensorFlow.js (jika berupa folder, zip dulu)
!zip -r tfjs_model.zip tfjs_model/
files.download('tfjs_model.zip')